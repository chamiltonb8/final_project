[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Python Package!",
    "section": "",
    "text": "Documentation here\nGet started here\nView the Streamlit App here"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "My Python Package!",
    "section": "Overview",
    "text": "Overview\nThis page documents the main public functions in the stat386stonks package, including what each function does, its inputs, and what it returns. These functions are designed to support a reproducible workflow for collecting, cleaning, analyzing, modeling, and visualizing historical stock data.\n\nNote: Function behavior is described based on the project’s implementation. Where relevant, functions assume standard Alpha Vantage weekly adjusted time series fields (e.g., open, close, adjusted close, volume) and the cleaned dataset produced by clean_prices()."
  },
  {
    "objectID": "index.html#data-collection",
    "href": "index.html#data-collection",
    "title": "My Python Package!",
    "section": "Data Collection",
    "text": "Data Collection\n\nfetch_weekly_adjusted(symbols)\nPurpose\nDownloads weekly adjusted time series data for a list of stock ticker symbols from the Alpha Vantage API and returns a single combined DataFrame.\nWhere it lives\nstat386stonks.read_data\nInputs - symbols (list[str]): A list of ticker symbols (e.g., [\"AAPL\", \"MSFT\", \"SPY\"]).\nWhat it does - Loads your Alpha Vantage API key from the environment (ALPHAVANTAGE_API_KEY), typically via a local .env file. - Calls the Alpha Vantage weekly adjusted endpoint for each symbol. - Builds a DataFrame for each symbol and concatenates results into one DataFrame (with a Symbol column). - Converts the date field to a proper datetime column and sorts by date.\nReturns - (pandas.DataFrame): Weekly stock data for all requested symbols, including a Symbol column and a Date column.\nExample\nfrom stat386stonks import fetch_weekly_adjusted\n\nsymbols = [\"AAPL\", \"MSFT\", \"SPY\"]\ndf_raw = fetch_weekly_adjusted(symbols)\ndf_raw.head()"
  },
  {
    "objectID": "index.html#cleaning-and-feature-engineering",
    "href": "index.html#cleaning-and-feature-engineering",
    "title": "My Python Package!",
    "section": "Cleaning and Feature Engineering",
    "text": "Cleaning and Feature Engineering\n\nclean_prices(df)\nPurpose\nCleans raw Alpha Vantage output and creates engineered features used throughout the project.\nWhere it lives\nstat386stonks.clean_data\nInputs - df (pandas.DataFrame): Raw (or semi-raw) stock data. Typically created by fetch_weekly_adjusted() or read from a CSV export.\nWhat it does - Standardizes column names (e.g., removes numeric prefixes like 1. open → open). - Converts numeric columns to numeric types (prices, volume, dividend amount, etc.). - Ensures Date is parsed as datetime and the data is sorted by Symbol and Date. - Creates engineered features: - Close_diff: week-to-week difference in close (within each Symbol) - Pct_Change: percent change in adjusted close relative to the first observation (within each Symbol)\nReturns - (pandas.DataFrame): A cleaned DataFrame with engineered features included.\nExample\nimport pandas as pd\nfrom stat386stonks import clean_prices\n\ndf_raw = pd.read_csv(\"data/weekly_5yr_all_symbols.csv\")\ndf_clean = clean_prices(df_raw)\ndf_clean[[\"Symbol\", \"Date\", \"close\", \"Close_diff\", \"Pct_Change\"]].head()"
  },
  {
    "objectID": "index.html#modeling",
    "href": "index.html#modeling",
    "title": "My Python Package!",
    "section": "Modeling",
    "text": "Modeling\n\nfit_next_return_models(df)\nPurpose\nFits per-stock linear regression models to predict next-period returns using simple signals from the current period.\nWhere it lives\nstat386stonks.models\nInputs - df (pandas.DataFrame): Cleaned stock data (ideally produced by clean_prices()), containing at least: - Symbol - Date - adjusted close - volume\nWhat it does - For each Symbol, computes: - ret: percent change of adjusted close - next_ret: ret shifted by -1 (the next period’s return) - vol_change: percent change of volume - Fits a time-based train/test split (no shuffling) to better reflect a forecasting scenario. - Trains a linear regression model: - Target: next_ret - Features: ret and vol_change - Computes evaluation metrics such as: - R² - Mean Squared Error (MSE) - Returns a compact summary table across symbols.\nReturns - (pandas.DataFrame): One row per symbol, typically including coefficients and metrics (e.g., coef_ret, coef_vol_change, intercept, r2, mse, n_obs).\nExample\nimport pandas as pd\nfrom stat386stonks import fit_next_return_models\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\nresults = fit_next_return_models(df)\nresults"
  },
  {
    "objectID": "index.html#visualization",
    "href": "index.html#visualization",
    "title": "My Python Package!",
    "section": "Visualization",
    "text": "Visualization\n\nplot_closing_prices(df)\nPurpose\nPlots adjusted closing prices over time for each stock symbol in the dataset.\nWhere it lives\nstat386stonks.plots\nInputs - df (pandas.DataFrame): Cleaned or raw stock data containing: - Symbol - Date - adjusted close\nWhat it does - Iterates over each symbol and produces a time-series line plot of adjusted close vs Date.\nReturns - None (displays plots).\nExample\nimport pandas as pd\nfrom stat386stonks import plot_closing_prices\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\nplot_closing_prices(df)\n\n\n\nplot_all_pct_change(df)\nPurpose\nPlots the percent change (Pct_Change) for all symbols on a single chart for easy comparison.\nWhere it lives\nstat386stonks.plots\nInputs - df (pandas.DataFrame): Cleaned stock data containing: - Symbol - Date - Pct_Change\nWhat it does - Plots each symbol’s Pct_Change vs Date on the same set of axes. - Useful for comparing growth trajectories across multiple stocks.\nReturns - None (displays plot).\nExample\nimport pandas as pd\nfrom stat386stonks import plot_all_pct_change\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\nplot_all_pct_change(df)\n\n\n\ncompare_two(stock1, stock2, df)\nPurpose\nCreates side-by-side style comparison plots for two stocks: 1) adjusted close over time\n2) percent change over time\nWhere it lives\nstat386stonks.plots\nInputs - stock1 (str): First ticker symbol (e.g., \"AAPL\"). - stock2 (str): Second ticker symbol (e.g., \"SPY\"). - df (pandas.DataFrame): Cleaned stock data containing: - Symbol - Date - adjusted close - Pct_Change\nWhat it does - Filters the dataset to the two requested symbols. - Plots: - adjusted close vs Date for both stocks - Pct_Change vs Date for both stocks\nReturns - None (displays plots).\nExample\nimport pandas as pd\nfrom stat386stonks import compare_two\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\ncompare_two(\"AAPL\", \"SPY\", df)"
  },
  {
    "objectID": "index.html#notes-for-streamlit-integration",
    "href": "index.html#notes-for-streamlit-integration",
    "title": "My Python Package!",
    "section": "Notes for Streamlit Integration",
    "text": "Notes for Streamlit Integration\nThe Streamlit dashboard can import these functions directly:\nfrom stat386stonks import clean_prices, fit_next_return_models\nFor interactive apps, it is common to: - load the cleaned CSV (fast) - cache the DataFrame in Streamlit (@st.cache_data) - compute summary tables using groupby operations (performance/volatility)"
  },
  {
    "objectID": "final_project/quartostuff.html",
    "href": "final_project/quartostuff.html",
    "title": "quartostuff",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "final_project/quartostuff.html#quarto",
    "href": "final_project/quartostuff.html#quarto",
    "title": "quartostuff",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Tutorial.html",
    "href": "Tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "the package is installable directly from GitHub.\n#| eval: false\npip install git+https://github.com/chamiltonb8/final_project.git\nAfter installing the package confirm that it works\n\nimport stat386stonks"
  },
  {
    "objectID": "Tutorial.html#install-the-package",
    "href": "Tutorial.html#install-the-package",
    "title": "Tutorial",
    "section": "",
    "text": "the package is installable directly from GitHub.\n#| eval: false\npip install git+https://github.com/chamiltonb8/final_project.git\nAfter installing the package confirm that it works\n\nimport stat386stonks"
  },
  {
    "objectID": "Tutorial.html#api-key-setup-required-for-data-collection",
    "href": "Tutorial.html#api-key-setup-required-for-data-collection",
    "title": "Tutorial",
    "section": "2. API Key setup (required for data collection)",
    "text": "2. API Key setup (required for data collection)\n\nobtain a free api key from the AlphaVantage Website\ncreate a .env file in your root directory and list it in a .gitignore file. Make sure that the call to the API in the .env file looks like this: ALPHAVANTAGE_API_KEY=your_key_here (just make sure to replace “your_key_here” with the key you obtain)\nThis package automatically adds this key using the python-dotenv library"
  },
  {
    "objectID": "Tutorial.html#collecting-stock-data",
    "href": "Tutorial.html#collecting-stock-data",
    "title": "Tutorial",
    "section": "3. Collecting Stock Data",
    "text": "3. Collecting Stock Data\nAll Stock Data is collected using the fetch_weekly_adjusted() function. It’s implementation looks like this:\n\n# Import the Library and function\nfrom stat386stonks import fetch_weekly_adjusted\n\n# Select the Symbols you want to use from the list you can edit it to use any ticker that you would like as long as you know the symbol and AlphaVangtage contains it. We'll use those listed in the list object. \nsymbols = [\"AAPL\", \"MSFT\", \"SPY\", \"TSLA\", \"GOOGL\", \"AMZN\", \"META\"]\n\n# Create a new dataframe that allows you to explore and analyze the stock data\ndf_raw = fetch_weekly_adjusted(symbols)\n\ndf_raw.head()\n\nThe code above returns a DataFrame containing weekly adjusted stock data for each selected symbol.\nFor reproduceability, we recommend that you save the raw data:\n\ndf_raw.to_csv(\"data/weekly_5yr_all_symbols.csv\", index=False)"
  },
  {
    "objectID": "Tutorial.html#cleaning-and-preparing-the-data",
    "href": "Tutorial.html#cleaning-and-preparing-the-data",
    "title": "Tutorial",
    "section": "4. Cleaning and Preparing the Data",
    "text": "4. Cleaning and Preparing the Data\nAs with all data, the raw data needs cleaning before it can be used. The Package provides a function that makes this step easier than if it was done by hand and allows for two options:\n\nOption A - In Python\n\nimport pandas as pd\nfrom stat386stonks import clean_prices\n\ndf_raw = pd.read_csv(\"data/weekly_5yr_all_symbols.csv\")\ndf_clean = clean_prices(df_raw)\n\ndf_clean.head()\n\n\n\nOption B - In Bash/Terminal\n#| eval: false\n./.venv/bin/python scripts/clean_prices.py \\\n  --infile data/weekly_5yr_all_symbols.csv \\\n  --outfile data/clean_weekly_stock_data.csv"
  },
  {
    "objectID": "Tutorial.html#feature-engineering",
    "href": "Tutorial.html#feature-engineering",
    "title": "Tutorial",
    "section": "5. Feature Engineering",
    "text": "5. Feature Engineering\nThe cleaning step creates additional variables automatically that can help in future analysis.\n\nClose_diff: Week-to-week change in closing price for each stock.\nPct_Change: Percent change in adjusted close price relative to the first observation for each stock.\n\nThese features allow comparisons across stocks and enable volatility and performance analysis."
  },
  {
    "objectID": "Tutorial.html#analysis-and-modeling",
    "href": "Tutorial.html#analysis-and-modeling",
    "title": "Tutorial",
    "section": "6. Analysis and Modeling",
    "text": "6. Analysis and Modeling\nThis Package Includes a modeling function to explore simple patterns in the stock data and can potentially aid in predicing future returns.\n\nimport pandas as pd\nfrom stat386stonks import fit_next_return_models\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\nresults = fit_next_return_models(df)\n\nresults\n\nThis function fits time-based linear regression models for each stock and returns model coefficients and performance metrics."
  },
  {
    "objectID": "Tutorial.html#visualization",
    "href": "Tutorial.html#visualization",
    "title": "Tutorial",
    "section": "7. Visualization",
    "text": "7. Visualization\nThe package provides several visualization utilities for exploratory analysis.\nHere is how to implement each one:\n\nPlot Adjusted Closing Prices\n\nfrom stat386stonks import plot_closing_prices\n\nplot_closing_prices(df)\n\n\n\nPlot percent change over time\n\nfrom stat386stonks import plot_all_pct_change\n\nplot_all_pct_change(df)\n\n\n\nCompare two stocks\n\nfrom stat386stonks import compare_two\n\ncompare_two(\"AAPL\", \"SPY\", df)\n\n\n\nNew plot"
  },
  {
    "objectID": "Tutorial.html#streamlit-dashboard",
    "href": "Tutorial.html#streamlit-dashboard",
    "title": "Tutorial",
    "section": "8. Streamlit Dashboard",
    "text": "8. Streamlit Dashboard\nAn interactive Streamlit application is included in the project. The app imports the stat386stonks package to display interactive plots and summary tables. There is also a link to it here\nTo run the app locally:\n#| eval: false\nstreamlit run streamlit_app.py"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "stat386stonks",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport requests\nimport os\nimport sklearn as sk\nfrom dotenv import load_dotenv\nimport time\nimport re\n\n\ndef read_data():\n    load_dotenv()\n    API_key = os.getenv('ALPHAVANTAGE_API_KEY')\n\n    symbols = [\"AAPL\", \"MSFT\", \"SPY\", \"TSLA\", \"GOOGL\", \"AMZN\", \"META\"]\n\n    base_url = \"https://www.alphavantage.co/query\"\n\n    all_data = []  # List to store each symbol's data\n\n    for symbol in symbols:\n        print(f\"Downloading weekly data for {symbol}...\")\n\n        params = {\n            \"function\": \"TIME_SERIES_WEEKLY_ADJUSTED\",\n            \"symbol\": symbol,\n            \"apikey\": API_key\n        }\n\n        for attempt in range(3):\n            r = requests.get(base_url, params=params)\n            try:\n                data = r.json()\n                break\n            except ValueError:\n                print(f\"Invalid response for {symbol}, attempt {attempt+1}\")\n                print(\"Raw response:\", r.text[:200])\n                time.sleep(15)\n        else:\n            print(f\"Failed to get valid JSON for {symbol}, skipping...\")\n            continue\n\n        if \"Weekly Adjusted Time Series\" not in data:\n            print(f\"Error for {symbol}: {data}\")\n            time.sleep(15)\n            continue\n\n        df = pd.DataFrame(data[\"Weekly Adjusted Time Series\"]).T\n\n        # Keep default integer index, create new column 'Date'\n        df['Date'] = pd.to_datetime(df.index)\n\n        # Sort by Date if needed\n        df = df.sort_values('Date')\n\n        df = df[df['Date'].between(pd.Timestamp(\"2015-12-04\"), pd.Timestamp(\"2020-12-04\"))]\n\n        df['Symbol'] = symbol\n        df.reset_index(drop=True, inplace=True)  # Drop old string index\n\n        all_data.append(df)\n        time.sleep(15)\n    return df\n\n\ndef combine_data():\n    df1 = pd.read_csv(\"weekly_5yr_all_symbols.csv\")\n    df2 = pd.read_csv(\"weekly_5yr_all_symbols_pt_2.csv\")\n\n    # Clean column names (remove leading numbers like \"1. Price\")\n    df1.columns = [re.sub(r'^\\d+\\.\\s*', '', col) for col in df1.columns]\n    df2.columns = [re.sub(r'^\\d+\\.\\s*', '', col) for col in df2.columns]\n\n    # Reorder columns of df1\n    df1 = df1[['Symbol', 'Date'] + [col for col in df1.columns if col not in ['Symbol', 'Date']]]\n\n    # Reorder df2 the same way to guarantee matching column order\n    df2 = df2[df1.columns]\n\n    # Combine the two\n    df = pd.concat([df1, df2], ignore_index=True)\n    df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)\n\n\ndef cleaning_pipeline(df):\n    df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)\n\n    # Clean column names (remove numbers like \"1. open\")\n    df.columns = [re.sub(r'^\\d+\\.\\s*', '', col) for col in df.columns]\n\n    # Reorder columns\n    df = df[['Symbol', 'Date'] + [col for col in df.columns if col not in ['Symbol', 'Date']]]\n    df['close'] = df['close'].astype(float)\n\n    # Sort by Symbol and Date to make sure diff works correctly\n    df = df.sort_values(['Symbol', 'Date'])\n\n    # Create a new column with difference from previous close\n    df['Close_diff'] = df.groupby('Symbol')['close'].diff()\n    \n    #Percentage Change from Beginning\n    df['Pct_Change'] = df.groupby('Symbol')['adjusted close'].transform(\n        lambda x: (x / x.iloc[0] - 1) * 100\n    )\n\n\ndf = pd.read_csv(\"data/clean_weekly_stock_data.csv\")\n\n\ndef plot_closing_prices(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    symbols = df['Symbol'].unique()\n\n    for sym in symbols:\n        sub = df[df['Symbol'] == sym]\n\n        plt.figure(figsize=(10,4))\n        plt.plot(sub['Date'], sub['adjusted close'])\n        plt.title(f\"Closing Price Over Time: {sym}\")\n        plt.ylabel(\"Closing Price\")\n        plt.tight_layout()\n        years = sorted(sub['Date'].dt.year.unique())\n        tick_locs = [pd.Timestamp(f'{y}-01-01') for y in years]\n        plt.xticks(ticks=tick_locs, labels=years, rotation=45)\n        plt.show()\n\n# Create a new column with difference from previous close\ndf['Close_diff'] = df.groupby('Symbol')['close'].diff()\n\nnumeric_cols = [\n    'open', 'high', 'low', 'close',\n    'adjusted close', 'volume',\n    'dividend amount'\n]\n\nfor col in numeric_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n\n\ndf.head()\n\n\n\n\n\n\n\n\nSymbol\nDate\nopen\nhigh\nlow\nclose\nadjusted close\nvolume\ndividend amount\nClose_diff\nPct_Change\n\n\n\n\n0\nAAPL\n2020-12-04\n116.97\n123.780\n116.810\n122.250\n119.0171\n541563385\n0.0\nNaN\n0.000000\n\n\n1\nAAPL\n2020-12-11\n122.31\n125.950\n120.150\n122.410\n119.1728\n452278651\n0.0\n0.160\n0.130822\n\n\n2\nAAPL\n2020-12-18\n122.60\n129.580\n121.540\n126.655\n123.3056\n621758148\n0.0\n4.245\n3.603264\n\n\n3\nAAPL\n2020-12-24\n125.02\n134.405\n123.449\n131.970\n128.4800\n433757134\n0.0\n5.315\n7.950874\n\n\n4\nAAPL\n2020-12-31\n133.99\n138.789\n131.720\n132.690\n129.1810\n439740666\n0.0\n0.720\n8.539865\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX = df[['close', 'volume']]\nY = df['adjusted close']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\npreds = model.predict(X_test)\n\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)\n\nprint(df.dtypes)\n\nCoefficients: [-3.46972730e-02 -1.78538931e-07]\nIntercept: 311.23486061236014\nSymbol              object\nDate                object\nopen               float64\nhigh               float64\nlow                float64\nclose              float64\nadjusted close     float64\nvolume               int64\ndividend amount    float64\nClose_diff         float64\nPct_Change         float64\ndtype: object\n\n\n\ndef plot_all_stocks_together(df,symbols=[\"AAPL\", \"MSFT\", \"SPY\", \"TSLA\", \"GOOGL\", \"AMZN\", \"META\"]):\n    plt.figure(figsize=(12,6))\n\n    for sym in symbols:\n        sub = df[df['Symbol'] == sym]\n        plt.plot(sub['Date'], sub['Pct_Change'], label=sym)\n\n    plt.title(\"Stock Closing Prices Over Time\")\n    plt.ylabel(\"Closing Price\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\nplot_all_stocks_together(df)\n\n\n\n\n\n\n\n\n\ndef plot_all_pct_change(df: pd.DataFrame, symbols=None):\n    df = df.copy()\n    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\n    if symbols is None:\n        symbols = df[\"Symbol\"].unique()\n\n    plt.figure(figsize=(12, 6))\n    for sym in symbols:\n        sub = df[df[\"Symbol\"] == sym].sort_values(\"Date\")\n        plt.plot(sub[\"Date\"], sub[\"Pct_Change\"], label=sym)\n\n    plt.title(\"Percent Change Over Time (All Stocks)\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Percent Change\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\nplot_all_pct_change(df)\n\n\n\n\n\n\n\n\n\n#comparing each stock to the SPY\ndef compare_stocks(stock1, stock2, df):\n    # Pull the data\n    s1 = df[df['Symbol'] == stock1].copy()\n    s2 = df[df['Symbol'] == stock2].copy()\n\n    # Ensure sorted\n    s1 = s1.sort_values(\"Date\")\n    s2 = s2.sort_values(\"Date\")\n\n    # -------------------------------\n    # 1) Closing Price Over Time\n    # -------------------------------\n    plt.figure(figsize=(12,5))\n    plt.plot(s1['Date'], s1['adjusted close'], label=stock1)\n    plt.plot(s2['Date'], s2['adjusted close'], label=stock2)\n\n    plt.title(f\"{stock1} vs {stock2} — Closing Price Over Time\")\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Closing Price\")\n\n    # Year tick labels only\n    years = sorted(df['Date'].dt.year.unique())\n    ticks = [pd.Timestamp(f\"{y}-01-01\") for y in years]\n    plt.xticks(ticks, years, rotation=45)\n\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n    # -------------------------------\n    # 2) Percentage Change Over Time\n    # -------------------------------\n    plt.figure(figsize=(12,5))\n    plt.plot(s1['Date'], s1['Pct_Change'], label=stock1)\n    plt.plot(s2['Date'], s2['Pct_Change'], label=stock2)\n\n    plt.title(f\"{stock1} vs {stock2} — Percentage Change Over Time\")\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Percentage Change\")\n\n    # Year tick labels only\n    plt.xticks(ticks, years, rotation=45)\n\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n\n#aggergate across all time and order stocks by which ones have performed best\nperformance = df.groupby('Symbol')['Pct_Change'].last().sort_values(ascending=False)\nprint(\"Stock Performance Over 5 Years:\")\nprint(performance)\n\nStock Performance Over 5 Years:\nSymbol\nGOOGL    253.558777\nMSFT     139.219887\nAAPL     134.294064\nMETA     133.074953\nTSLA     115.429688\nSPY       98.254902\nAMZN      47.487178\nName: Pct_Change, dtype: float64\n\n\n\n# Volatility Analysis\nvolatility = df.groupby('Symbol')['Close_diff'].std().sort_values(ascending=False)\nprint(\"\\nStock Volatility (Standard Deviation of Weekly Close Differences):\")\nprint(volatility)\n\n\nStock Volatility (Standard Deviation of Weekly Close Differences):\nSymbol\nAMZN     162.167585\nGOOGL    143.205635\nTSLA      56.950281\nMETA      20.343873\nMSFT      11.069256\nSPY       10.546683\nAAPL       6.821088\nName: Close_diff, dtype: float64\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_theme(style=\"whitegrid\")\n\nresults = []\n\nfor symbol, g in df.groupby('Symbol'):\n    g = g.sort_values('Date').copy()\n\n    # --- Create Return Columns ---\n    g['ret'] = g['adjusted close'].pct_change()\n    g['next_ret'] = g['ret'].shift(-1)\n    g['vol_change'] = g['volume'].pct_change()\n\n    # keep clean rows\n    g = g.dropna(subset=['ret', 'next_ret', 'vol_change'])\n    if len(g) &lt; 10:\n        continue\n\n    # features and target\n    X = g[['ret', 'vol_change']]\n    Y = g['next_ret']\n\n    # time-based split\n    split_idx = int(len(g) * 0.8)\n    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n    Y_train, Y_test = Y.iloc[:split_idx], Y.iloc[split_idx:]\n\n    # linear regression\n    model = LinearRegression()\n    model.fit(X_train, Y_train)\n    preds = model.predict(X_test)\n\n    # store results\n    results.append({\n        'Symbol': symbol,\n        'coef_ret': model.coef_[0],\n        'coef_vol_change': model.coef_[1],\n        'intercept': model.intercept_,\n        'r2': r2_score(Y_test, preds),\n        'mse': mean_squared_error(Y_test, preds),\n        'n_obs': len(g)\n    })\n\n    # --- Scatterplot: ret vs next_ret ---\n    plt.figure(figsize=(6, 4))\n    sns.scatterplot(data=g, x='ret', y='next_ret', alpha=0.6)\n    plt.title(f\"{symbol} Return vs Next-Period Return\")\n    plt.xlabel(\"This Period Return\")\n    plt.ylabel(\"Next Period Return\")\n    plt.axhline(0, linestyle='--', linewidth=0.8)\n    plt.axvline(0, linestyle='--', linewidth=0.8)\n    plt.tight_layout()\n    plt.show()\n\n    # --- Actual vs Predicted ---\n    plot_df = g.iloc[split_idx:].copy()\n    plot_df['Actual'] = Y_test.values\n    plot_df['Predicted'] = preds\n\n    plt.figure(figsize=(8, 5))\n    sns.lineplot(data=plot_df, x='Date', y='Actual', label='Actual')\n    sns.lineplot(data=plot_df, x='Date', y='Predicted', label='Predicted')\n    plt.title(f\"{symbol} Actual vs Predicted Returns\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Return\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\nresults_df = pd.DataFrame(results)\nresults_df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\ncoef_ret\ncoef_vol_change\nintercept\nr2\nmse\nn_obs\n\n\n\n\n0\nAAPL\n-0.051591\n-0.003746\n0.004285\n0.015894\n0.002005\n259\n\n\n1\nAMZN\n-0.035565\n-0.002252\n0.002782\n0.006479\n0.001831\n259\n\n\n2\nGOOGL\n-0.188897\n0.003452\n0.004194\n-0.065958\n0.002168\n259\n\n\n3\nMETA\n-0.055832\n-0.007595\n0.006115\n0.000771\n0.002606\n259\n\n\n4\nMSFT\n-0.084277\n0.001665\n0.004286\n0.010387\n0.001083\n259\n\n\n5\nSPY\n-0.092630\n-0.000333\n0.003208\n0.032825\n0.000551\n259\n\n\n6\nTSLA\n0.028931\n-0.001242\n0.005950\n0.001189\n0.005211\n259"
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation for the stat386stonks package",
    "section": "",
    "text": "We created this package so that people can analyze historical data from some of the most well-known stocks, compare them to each other, and use models to predict what stock prices may be in the future. Predicting the stock market is a dream for almost everyone involved in investing. Knowing the future would allow investors to make immense profits. Although the predictive models we added do not give exact predictions and can be wrong, they provide insight into what future stock prices may look like based on historical data. We want to disclose that these models are not perfect, and one should not carelessly invest in the stocks included in our package solely based on our models."
  },
  {
    "objectID": "Documentation.html#introduction",
    "href": "Documentation.html#introduction",
    "title": "Documentation for the stat386stonks package",
    "section": "",
    "text": "We created this package so that people can analyze historical data from some of the most well-known stocks, compare them to each other, and use models to predict what stock prices may be in the future. Predicting the stock market is a dream for almost everyone involved in investing. Knowing the future would allow investors to make immense profits. Although the predictive models we added do not give exact predictions and can be wrong, they provide insight into what future stock prices may look like based on historical data. We want to disclose that these models are not perfect, and one should not carelessly invest in the stocks included in our package solely based on our models."
  },
  {
    "objectID": "Documentation.html#preparing-the-data",
    "href": "Documentation.html#preparing-the-data",
    "title": "Documentation for the stat386stonks package",
    "section": "Preparing the Data",
    "text": "Preparing the Data\n\nAcquiring the Data\nThe dataset comes from the Alpha Vantage API, which provides publicly accessible financial market data, including historical and real-time prices for stocks, ETFs, cryptocurrencies, and forex. For this project, we only use historical stock prices. The data includes key information such as open, high, low, and close prices, trading volume, and adjusted close values for equities, along with metadata like the ticker symbol, time interval, and last refreshed date. The API allows data to be grouped by daily, weekly, or monthly intervals.\nAccessing the API requires creating a free Alpha Vantage account, and data collection is legal as long as it is not used for commercial purposes and rate limits are respected. Because the free API has usage limits, we collected data in two stages: first retrieving five years of weekly data for seven stocks and saving it to a CSV file, then modifying the code to retrieve the next five years of data and saving it to a separate CSV file. These two CSV files were then combined into a single dataset, which we used for data cleaning. We also chose to use weekly data instead of daily data in order to maximize the amount of historical data we could obtain within the API’s free limits while still capturing meaningful trends.\n\n\nCleaning the Data\nSome data cleaning occurred during the process of combining the two CSV files. The column names originally contained numbers at the beginning, which we removed so that only the column names remained and were consistently capitalized. We also ensured that the data was sorted first by stock symbol and then by date so that time series plots would be accurate. Without this step, the graphs and analysis would not reflect the true trends in the data.\nWe added two new variables using information from the API. The first was Close_diff, which groups the data by stock and computes the difference in adjusted closing price between the current week and the previous week. The adjusted closing price accounts for events such as stock splits, which occurred for some of the stocks in our dataset and would otherwise distort the analysis.\nThe second variable we created was Pct_Change, which groups the data by stock and calculates the percent change in adjusted closing price relative to the first data point for that stock. This allows for better comparisons across stocks, as percent growth is more meaningful to investors than raw price levels."
  },
  {
    "objectID": "Documentation.html#analysis",
    "href": "Documentation.html#analysis",
    "title": "Documentation for the stat386stonks package",
    "section": "Analysis",
    "text": "Analysis\n\nPlotting\nWhen comparing adjusted closing prices across the stocks we analyzed, ordered from highest to lowest, the ranking is the S&P 500, Meta, Microsoft, Tesla, Google, Apple, and Amazon. This ranking reflects prices as of approximately 12/1/25, when we last retrieved data from the API. This ordering is very similar to what it was ten years ago, with the main exception being Tesla, which rose from near the bottom to become the fourth-highest stock among the seven analyzed. The remaining stocks maintained similar rankings or were very close to one another.\n\n\n\nClose Price All Stocks\n\n\nThe graphs also show a sizable decrease in stock prices from approximately 2022 to 2024. This decline aligns with a period of extremely high inflation driven by post-pandemic supply chain disruptions and strong consumer demand supported by earlier stimulus efforts.\nComparing stocks based on their percent change over the last ten years, all of them experienced substantial growth, with the lowest increase around 286% and the highest near 2700%. Ordered from highest to lowest growth over the ten-year period, the ranking is Tesla, Apple, Microsoft, Google, Amazon, Meta, and the S&P 500. We were surprised to see that the S&P 500 achieved only about half the growth of Meta, the second-lowest stock in this ranking. This result is reasonable, however, since the individual stocks analyzed are primarily technology companies that have experienced significant growth over the past decade, whereas the S&P 500 represents a diversified index of the top 500 companies and is generally considered a safer, but still rewarding, investment.\n\n\n\nPercent Change All Stocks\n\n\n\n\nSummary Tables\nWe included summary tables to display numerical values for percent change, volatility, and the mean weekly percent increase for each stock.\nVolatility measures how unpredictable a stock’s price movements are and provides insight into its risk level. Higher volatility indicates larger and more frequent price changes, while lower volatility suggests greater stability and potentially lower risk for long-term investors. From highest to lowest volatility, the stocks are Amazon, Google, Tesla, Apple, Meta, the S&P 500, and Microsoft. We were surprised that Tesla did not have the highest volatility, since the graphs show large price swings that visually appear very extreme. However, while Tesla’s volatility is still relatively high as the third most volatile stock, its value is around 95, compared to Apple’s volatility of only 18. We were also surprised to see that the S&P 500, often considered the safest long-term investment option, did not have the lowest volatility—Microsoft did. That said, the difference between their volatilities was less than one standard deviation, so they are not drastically different.\nThe final statistic we examined was the mean weekly percent increase in a stock’s closing price. This metric provides a long-term view of price trends and momentum while smoothing out some of the short-term “noise” present in the stock market. It helps estimate how much a stock might be expected to increase on an average week. This information can be useful for both short-term and long-term investors. A high average weekly increase may appeal to short- or medium-term investors, even if the stock is more volatile, while also offering reassurance to long-term investors that growth is occurring consistently over time."
  },
  {
    "objectID": "Documentation.html#modeling",
    "href": "Documentation.html#modeling",
    "title": "Documentation for the stat386stonks package",
    "section": "Modeling",
    "text": "Modeling\nTo Explore more about whether or not historical stock data has predictive information, we decided to fit a liner regression model at each individual stock level. Weekly returns were computed from adjusted closing prices, and the response variable was defined as the next-period return. Two predictors were used: the current-period return and the percent change in trading volume. These features were chosen because they are easily interpretable and commonly used in other financial analysis.\nModels were trained by using a time-based train/test split to preserve the data sctructures and better relflect a forecasting setting. Model performace is evaluated using the standard metrics of R^2 and MSE. Overall, the results indicated that predictive power is limited. Because the market is so volatile. the modeling component now focuses more on EDA and a baseline of demonstrating how statiscal models can be implemented to these data and in the data science pipline."
  },
  {
    "objectID": "Documentation.html#conclusion",
    "href": "Documentation.html#conclusion",
    "title": "Documentation for the stat386stonks package",
    "section": "Conclusion",
    "text": "Conclusion\nFrom our analysis, we found that Tesla experienced the largest increase over the past ten years among the seven stocks examined. Surprisingly, the S&P 500 did not perform as strongly as expected when compared to major individual stocks such as Tesla, Apple, Microsoft, Google, Meta, and Amazon.\n[Write about modeling]\nThis analysis could be improved by using daily stock prices instead of weekly prices; however, we were limited by the amount of data available through the free API. The study could also be expanded by including stocks outside of the S&P 500, or stocks that experienced extreme short-term gains followed by large losses, such as GameStop. Including a wider variety of stocks would provide a broader perspective, allow for deeper insights, and help make the predictive models more generalizable by better capturing market noise and volatility."
  }
]